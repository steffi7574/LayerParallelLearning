################################
# Learning problem  
################################

# number of training data elements
ntraining = 5000
# number of validation data elements
nvalidation = 200
# number of features in training and validation data 
nfeatures = 2 
# number of classes
nclasses = 5 
# number of channels
nchannels = 8
# number of layers 
nlayers = 32
# final time
T = 10.0
# Activation function ("ReLu" or "tanh")
activation = ReLu
# Apply opening layer sigma(KY+mu) ("YES" or "NO"). If NO: expands data to channels using zeros.
openinglayer = YES
# factor for scaling initial opening layer weights and bias
weights_open_init = 1e-3
# factor for scaling initial weights and bias 
weights_init = 0e-3
# factor for scaling initial classification weights and bias 
weights_class_init = 1e-3

################################
#BRAID 
################################

# coarsening factor
braid_cfactor = 2 
# maximum number of levels 
braid_maxlevels = 1
# maximum number of iterations
braid_maxiter = 10
# absolute tolerance
braid_abstol = 1e-10
# absolute adjoint tolerance
braid_adjtol = 1e-6
# printlevel
braid_printlevel = 1 
# access level
braid_accesslevel = 0 
# skip work on downcycle?
braid_setskip = 0 
# V-cycle (0) or full multigrid  (1)
braid_fmg = 1 
# Number of CF relaxations
braid_nrelax = 2 

####################################
#Optimization
####################################

# relaxation param for theta tikhonov term
gamma_theta_tik = 1e-7
# relaxation param for theta time-derivative term
gamma_theta_ddt = 1e-7
# relaxation term for classifier
gamma_class = 1e-3
# initial stepsize
stepsize = 1.0
# maximum number of optimization iterations
optim_maxiter = 200
# absolute stopping criterion for the gradient norm
gtol = 1e-4
# maximum number of linesearch iterations
ls_maxiter = 20
# factor for modifying the stepsize within a linesearch iteration
ls_factor = 0.5


# Hessian Approximation ("BFGS" or "L-BFGS")
hessian_approx = L-BFGS
# number of stages for l-bfgs method 
lbfgs_stages = 5

